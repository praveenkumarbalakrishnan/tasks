{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveenkumarbalakrishnan/tasks/blob/main/SIG731_Data_Wrangling_Task8HD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfgWZGJdopjD"
      },
      "source": [
        "**Title:** Task 8HD: SIG731-Data Wrangling\n",
        "\n",
        "**Name:** Praveenkumar Balakrishnan\n",
        "\n",
        "**Student Number:** 223029369\n",
        "\n",
        "**Email Address:** s223029369@deakin.edu.au\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXFHK_42wGqy"
      },
      "source": [
        "# Import statements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM7GB7mEEDPm",
        "outputId": "1b8fff49-8f02-4683-eb99-4852e44b494d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_oYjhYMQ63Pu"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "import xml.etree.cElementTree as cetree\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc1aMsOTqTUH"
      },
      "source": [
        "# Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selected Movies & TV dataset for this analysis"
      ],
      "metadata": {
        "id": "QGJuO8DFfcG4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOQjDIHLqgwk"
      },
      "source": [
        "**Task 1**\n",
        "\n",
        "Convert all the data tables (Badges, Comments, PostHistory, PostLinks, Posts, Tags, Users, Votes)\n",
        "from XML to CSV, using custom code that you write yourself. Ideally, you should write a Python\n",
        "function that takes a single input file name (.xml) and output file name (.csv) and performs the\n",
        "conversion of a single dataset.\n",
        "\n",
        "**Task 2**\n",
        "\n",
        "Load the CSV files as pandas data frames\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Column names for 8 dataset based on the schema documentation"
      ],
      "metadata": {
        "id": "Ldei0mbpg0-u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "dHqaonCdLKaB"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/Inputs/'\n",
        "\n",
        "badges_cols = ['Id', 'UserId', 'Name', 'Date', 'Class', 'TagBased']\n",
        "comments_cols = [\n",
        "    'Id', 'PostId', 'Score', 'Text', 'CreationDate', 'UserDisplayName',\n",
        "    'UserId', 'ContentLicense']\n",
        "post_history_cols = [\n",
        "    'Id', 'PostHistoryTypeId', 'PostId', 'RevisionGUID', 'CreationDate',\n",
        "    'UserId', 'UserDisplayName', 'Comment', 'Text', 'ContentLicense']\n",
        "post_links_cols = [\n",
        "    'Id', 'CreationDate', 'PostId', 'RelatedPostId', 'LinkTypeId']\n",
        "posts_cols = [\n",
        "    'Id', 'PostTypeId', 'AcceptedAnswerId', 'ParentId', 'CreationDate',\n",
        "    'DeletionDate', 'Score', 'ViewCount', 'Body', 'OwnerUserId',\n",
        "    'OwnerDisplayName', 'LastEditorUserId', 'LastEditorDisplayName',\n",
        "    'LastEditDate', 'LastActivityDate', 'Title', 'Tags', 'AnswerCount',\n",
        "    'CommentCount', 'FavoriteCount', 'ClosedDate', 'CommunityOwnedDate',\n",
        "    'ContentLicense']\n",
        "tags_cols = [\n",
        "    'Id', 'TagName', 'Count', 'ExcerptPostId', 'WikiPostId',\n",
        "    'IsModeratorOnly', 'IsRequired']\n",
        "users_cols = [\n",
        "    'Id', 'Reputation', 'CreationDate', 'DisplayName', 'LastAccessDate',\n",
        "    'WebsiteUrl', 'Location', 'AboutMe', 'Views', 'UpVotes', 'DownVotes',\n",
        "    'ProfileImageUrl', 'AccountId']\n",
        "votes_cols = [\n",
        "    'Id', 'PostId', 'VoteTypeId', 'UserId',  'CreationDate', 'BountyAmount']\n",
        "\n",
        "meta_dict = {\n",
        "    'Badges': badges_cols, 'Comments': comments_cols,\n",
        "    'PostHistory': post_history_cols, 'PostLinks': post_links_cols,\n",
        "    'Posts': posts_cols, 'Tags': tags_cols, 'Users': users_cols,\n",
        "    'Votes': votes_cols}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parsed the xml elements, iterated in a loop and applied the regex functions to remove extra tags and other characters then load it in a csv file"
      ],
      "metadata": {
        "id": "jLvB9SLbFBLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(xml_file_name, cols_list):\n",
        "    \"\"\"\n",
        "    This generator is to parse the xml data and yield as a row\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    file_name: str\n",
        "      Input xml file name\n",
        "    cols: list\n",
        "      Column names of the input files\n",
        "    \n",
        "    Yield\n",
        "    ------\n",
        "    row: str\n",
        "      Row from xml data\n",
        "    \"\"\"\n",
        "    col_names = ''\n",
        "    for col in cols_list:\n",
        "      col_names = col_names + col + '|'\n",
        "    col_names = col_names[:-1] + '\\n'\n",
        "    yield col_names\n",
        "\n",
        "    for event, elem in cetree.iterparse(xml_file_name):\n",
        "      row = ''\n",
        "      if elem.tag == \"row\":\n",
        "        for col in cols_list:\n",
        "          if col in elem.attrib:\n",
        "              val = elem.attrib[col].replace(\"|\", \" \").replace('\\n', ' ')\n",
        "              if col in ['Tags']:\n",
        "                val = re.sub(r'<', '', val)\n",
        "                val = re.sub(r'>', ' ', val)\n",
        "              else:\n",
        "                val = re.sub(r'<.?>', '', val)\n",
        "                val = re.sub('[^A-Za-z0-9-:.]+', ' ', val)\n",
        "                val = re.sub(' +', ' ', val)\n",
        "              row = row + val.rstrip(' p') + '|'\n",
        "          else:\n",
        "              row = row + '|'\n",
        "        row = row[:-1] + '\\n'\n",
        "        yield row\n",
        "        elem.clear()\n",
        "\n",
        "def convert_xml_to_csv(file_name, cols_list, path):\n",
        "  \"\"\"\n",
        "  This function is to convert xml to csv and write as csv file\n",
        "  and upper value\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  file_name: str\n",
        "    Input filename without the extension like \".xml\"\n",
        "  cols: list\n",
        "    Column names of the input files\n",
        "  \n",
        "  Return\n",
        "  ------\n",
        "  csv_filename: str\n",
        "    Output csv filename\n",
        "  \"\"\"\n",
        "  xml_file_name = os.path.join(path, file_name + '.xml')\n",
        "  output_file_name = os.path.join(path, file_name + '.csv')\n",
        "\n",
        "  data = get_data(xml_file_name, cols_list)\n",
        "  with open(output_file_name, 'w') as f:\n",
        "      for item in data:\n",
        "          f.write(item)\n",
        "  return output_file_name"
      ],
      "metadata": {
        "id": "gjXxl6GtL3A6"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Invoked xml conversion function and got the filename then used pandas read_csv to load the data into separate dataframes.\n",
        "Note: Used dictionary to store the dataframe in the loop"
      ],
      "metadata": {
        "id": "4Rgiat_ZF1fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict = {}\n",
        "for k, v in meta_dict.items():\n",
        "  csv_file_name = convert_xml_to_csv(k, v, file_path)\n",
        "  data_dict[k] = pd.read_csv(csv_file_name, delimiter='|')"
      ],
      "metadata": {
        "id": "zOblOd1PYAJX"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loaded the dataframe to join in the upcoming step"
      ],
      "metadata": {
        "id": "G8mqvzznGYDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "badges_df = data_dict['Badges']\n",
        "comments_df = data_dict['Comments']\n",
        "post_history_df = data_dict['PostHistory']\n",
        "post_links_df = data_dict['PostLinks']\n",
        "posts_df = data_dict['Posts']\n",
        "tags_df = data_dict['Tags']\n",
        "users_df = data_dict['Users']\n",
        "votes_df = data_dict['Votes']"
      ],
      "metadata": {
        "id": "E0n_KOOQ5RXf"
      },
      "execution_count": 156,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHd2rSVI5VBVS9AgHPANrb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}